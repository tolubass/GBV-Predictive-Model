{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4068ada6-dc62-4c3e-85b7-ff81aeaeef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5aa8ac-6e9f-46fa-8cab-c19f3c91c619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vulnerability_target\n",
      "0    31002\n",
      "1    13348\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"final_encoded_gbv.csv\")\n",
    "\n",
    "# Quick class check (optional)\n",
    "print(df['vulnerability_target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8957fc5-448c-4124-9ba3-ad03985e50bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority class shape: (13348, 55)\n",
      "Detected 27 binary columns.\n",
      "Input dimension: 55\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(\"vulnerability_target\", axis=1)\n",
    "y = df[\"vulnerability_target\"]\n",
    "\n",
    "# Extract minority class (1)\n",
    "minority_data = X[y == 1].copy()\n",
    "print(\"Minority class shape:\", minority_data.shape)\n",
    "\n",
    "# Identify binary (0/1) columns based on the minority portion\n",
    "# (keeps one-hot columns clean after generation)\n",
    "binary_cols = []\n",
    "for col in minority_data.columns:\n",
    "    vals = pd.Series(minority_data[col].dropna().unique())\n",
    "    # treat 0.0/1.0 as binary too\n",
    "    if set(vals.astype(float).round().unique()).issubset({0.0, 1.0}) and vals.nunique() <= 2:\n",
    "        binary_cols.append(col)\n",
    "\n",
    "print(f\"Detected {len(binary_cols)} binary columns.\")\n",
    "\n",
    "# Store min/max per column for clipping synthetic values into real ranges\n",
    "col_mins = minority_data.min(axis=0)\n",
    "col_maxs = minority_data.max(axis=0)\n",
    "\n",
    "# Convert to numpy (NO SCALING)\n",
    "minority_np = minority_data.values.astype(np.float32)\n",
    "\n",
    "# Input dimension for GAN\n",
    "input_dim = minority_np.shape[1]\n",
    "print(\"Input dimension:\", input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402e745d-ec39-4702-98f8-9da4c4de2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, noise_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Initialize models & optimizers\n",
    "noise_dim = 64\n",
    "generator = Generator(input_dim=input_dim, noise_dim=noise_dim)\n",
    "discriminator = Discriminator(input_dim=input_dim)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fdd735-7204-42bb-a5d2-b4b11c9f3100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D Loss=0.7427, G Loss=0.6468\n",
      "Epoch 500: D Loss=100.0186, G Loss=4.0124\n",
      "Epoch 1000: D Loss=100.0022, G Loss=6.1369\n",
      "Epoch 1500: D Loss=100.0007, G Loss=7.2420\n",
      "Epoch 2000: D Loss=100.0003, G Loss=7.9677\n",
      "Epoch 2500: D Loss=100.0002, G Loss=8.5768\n"
     ]
    }
   ],
   "source": [
    "# Convert minority data to torch tensor (no scaling)\n",
    "minority_tensor = torch.tensor(minority_np, dtype=torch.float32)\n",
    "\n",
    "epochs = 3000\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # === Train Discriminator ===\n",
    "    idx = np.random.randint(0, minority_tensor.shape[0], size=batch_size)\n",
    "    real_data = minority_tensor[idx]\n",
    "    real_labels = torch.ones(batch_size, 1)\n",
    "\n",
    "    z = torch.randn(batch_size, noise_dim)\n",
    "    fake_data = generator(z).detach()\n",
    "    fake_labels = torch.zeros(batch_size, 1)\n",
    "\n",
    "    d_real = discriminator(real_data)\n",
    "    d_fake = discriminator(fake_data)\n",
    "\n",
    "    d_loss_real = criterion(d_real, real_labels)\n",
    "    d_loss_fake = criterion(d_fake, fake_labels)\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    discriminator.zero_grad()\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "\n",
    "    # === Train Generator ===\n",
    "    z = torch.randn(batch_size, noise_dim)\n",
    "    generated = generator(z)\n",
    "    g_loss = criterion(discriminator(generated), torch.ones(batch_size, 1))\n",
    "\n",
    "    generator.zero_grad()\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch}: D Loss={d_loss.item():.4f}, G Loss={g_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25181d85-d4c3-418a-a3bb-dd4e7c880776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data shape: (17000, 56)\n"
     ]
    }
   ],
   "source": [
    "# How many synthetic samples?\n",
    "num_to_generate = 17000\n",
    "\n",
    "# Generate\n",
    "z = torch.randn(num_to_generate, noise_dim)\n",
    "generated_data = generator(z).detach().cpu().numpy()\n",
    "\n",
    "# Put into a DataFrame\n",
    "synthetic_df = pd.DataFrame(generated_data, columns=X.columns)\n",
    "\n",
    "# --- Post-process to keep data usable for models ---\n",
    "\n",
    "# (A) Clip each column to the real minority's min/max to avoid extreme values\n",
    "for col in synthetic_df.columns:\n",
    "    synthetic_df[col] = np.clip(\n",
    "        synthetic_df[col],\n",
    "        col_mins[col],\n",
    "        col_maxs[col]\n",
    "    )\n",
    "\n",
    "# (B) Force binary columns back to 0/1 using threshold 0.5\n",
    "if len(binary_cols) > 0:\n",
    "    synthetic_df[binary_cols] = (synthetic_df[binary_cols] >= 0.5).astype(int)\n",
    "\n",
    "# Add target label\n",
    "synthetic_df['vulnerability_target'] = 1\n",
    "\n",
    "print(\"Synthetic data shape:\", synthetic_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f891247f-45b2-43ad-bab8-ea17aee33c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBalanced dataset shape: (61350, 56)\n",
      "RBalanced class distribution:\n",
      " vulnerability_target\n",
      "0    31002\n",
      "1    30348\n",
      "Name: count, dtype: int64\n",
      "RBalanced dataset saved as 'balanced_gbv_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Original splits\n",
    "majority_df = df[df['vulnerability_target'] == 0]\n",
    "minority_df_real = df[df['vulnerability_target'] == 1]\n",
    "\n",
    "# Combine\n",
    "balanced_df = pd.concat([majority_df, minority_df_real, synthetic_df], ignore_index=True)\n",
    "\n",
    "# Shuffle\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"RBalanced dataset shape:\", balanced_df.shape)\n",
    "print(\"RBalanced class distribution:\\n\", balanced_df['vulnerability_target'].value_counts())\n",
    "\n",
    "# Save\n",
    "balanced_df.to_csv(\"RBalanced_gbv_data.csv\", index=False)\n",
    "print(\"RBalanced dataset saved as 'balanced_gbv_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6781c-ef5d-412f-8326-ba219274328e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
